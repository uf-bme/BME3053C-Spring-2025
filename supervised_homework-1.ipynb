{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification\n",
    "##### In this assignment, you will work with the [MNIST handwritten digits dataset](http://yann.lecun.com/exdb/mnist/) to implement and compare two supervised learning algorithms: Logistic Regression and Neural Networks. You will gain hands-on experience with data preprocessing, model training, evaluation, and visualization techniques commonly used in machine learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.11.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'c:/Users/Michelle/AppData/Local/Microsoft/WindowsApps/python3.11.exe -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    import seaborn as sns\n",
    "except ImportError as e:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    print(f\"Missing package: {str(e).split()[-1]}\")\n",
    "    print(\"Installing required packages...\")\n",
    "    %pip install scikit-learn\n",
    "    %pip install seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Data Loading and Exploration (4 points)\n",
    "1. Load the MNIST dataset using fetch_openml\n",
    "2. Print the following dataset characteristics:\n",
    "   - Dataset dimensions and size\n",
    "   - Number of classes\n",
    "3. Visualize sample digits from the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide your code for part 1-1 here\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide your code for part 1-2 here\n",
    "# print dataset dimensions and size\n",
    "print(f\"Dataset dimensions: {mnist.data.shape}\")\n",
    "print(f\"Dataset size: {mnist.data.size}\")\n",
    "# print number of classes\n",
    "print(f\"Number of classes: {len(np.unique(mnist.target))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Provide your code for part 1-3 here\n",
    "def plot_digits(data, labels, n=10):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        ax.imshow(data[i].reshape(28, 28), cmap='gray')\n",
    "        ax.set_title(f\"Label: {labels[i]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "plot_digits(mnist.data, mnist.target, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Data Preprocessing (4 points)\n",
    "1. Scale the pixel values to range [0,1] by dividing by 255\n",
    "2. Split the data into training (80%) and testing (20%) sets\n",
    "3. Create a StandardScaler object and fit it on the training data\n",
    "4. Transform both training and test data using the fitted scaler\n",
    "5. Print the shapes of the resulting training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your code for part 2 here\n",
    "# Provide your code for part 2 here\n",
    "# scale the pixel values to range [0, 1] by dividing by 255\n",
    "mnist.data = mnist.data / 255.0\n",
    "# split the data into training (80%) and testing (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state=42)\n",
    "# create a standardscaler object and fit it to the training data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "# transform both training and testing data using the fitted scaler\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# print the shapes of the resulting training and test sets\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Model Training and Evaluation (8 points)\n",
    "1. Train a Logistic Regression model using the training data. Use the default parameters.\n",
    "2. Train a Neural Network model using the training data. The neural network should have 2 hidden layers with 100 and 50 neurons respectively. Use the Adam optimizer and a learning rate of 0.001."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your code for part 3-1 here\n",
    "# Provide your code for part 3-1 here\n",
    "# train a logistic regression model using training data. use the default parameters\n",
    "log_reg = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your code for part 3-2 here\n",
    "# train a neural network model using training data. The neural network should have 2 hidden layers with 100 and 50 neurons respectively. Use the adam optimizer and a learning rate of 0.001\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', learning_rate_init=0.001, max_iter=1000)\n",
    "nn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Model Comparison and Visualization (4 points)\n",
    "1. Use a bar plot to compare the accuracy of both models on the test data\n",
    "2. Print the classification report and confusion matrix for both models\n",
    "3. Visualize the misclassified examples for both models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your code for part 4-1 here\n",
    "# Provide your code for part 4-1 here\n",
    "# use a bar plot to compare the accuracy of the two models on the test set\n",
    "log_reg_pred = log_reg.predict(X_test)\n",
    "nn_pred = nn_model.predict(X_test)\n",
    "log_reg_accuracy = accuracy_score(y_test, log_reg_pred)\n",
    "nn_accuracy = accuracy_score(y_test, nn_pred)\n",
    "# create a bar plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(['Logistic Regression', 'Neural Network'], [log_reg_accuracy, nn_accuracy], color=['blue', 'orange'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your code for part 4-2 here\n",
    "# Provide your code for part 4-2 here\n",
    "# print the classification report and confusion matrix for both models\n",
    "log_reg_report = classification_report(y_test, log_reg_pred)\n",
    "nn_report = classification_report(y_test, nn_pred)\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(log_reg_report)\n",
    "print(\"Neural Network Classification Report:\")\n",
    "print(nn_report)\n",
    "# confusion matrix for logistic regression\n",
    "log_reg_cm = confusion_matrix(y_test, log_reg_pred)\n",
    "# confusion matrix for neural network\n",
    "nn_cm = confusion_matrix(y_test, nn_pred)\n",
    "# plot confusion matrix for logistic regression\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(log_reg_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "# plot confusion matrix for neural network\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(nn_cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Neural Network Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide your code for part 4-3 here\n",
    "# visualize the misclassified samples for both models\n",
    "def plot_misclassified(X, y_true, y_pred, n=10):\n",
    "    misclassified = np.where(y_true != y_pred)[0]\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    for i in range(n):\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        ax.imshow(X[misclassified[i]].reshape(28, 28), cmap='gray')\n",
    "        ax.set_title(f\"True: {y_true[misclassified[i]]}\\nPred: {y_pred[misclassified[i]]}\")\n",
    "        ax.axis('off')\n",
    "    plt.show()\n",
    "plot_misclassified(X_test, y_test, log_reg_pred, n=10)\n",
    "plot_misclassified(X_test, y_test, nn_pred, n=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
